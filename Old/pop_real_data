import pandas as pd
import numpy as np
from datetime import date
from supabase import create_client, Client
import random

# --- Your Supabase Connection Info ---
url = "https://sywxhehahunevputgxdd.supabase.co"
key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InN5d3hoZWhhaHVuZXZwdXRneGRkIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTczMDQxNDEsImV4cCI6MjA3Mjg4MDE0MX0.SGNrmklPobim7-zb4zs78e2i2VRrmV84gV7DIl2m5s8"

supabase: Client = create_client(url, key)

# --- THE FIX: Extend the date range to over 2 years ---
START_DATE = date(2023, 9, 1) 
END_DATE = date(2025, 12, 31) 
# --- END FIX ---



def generate_gold_standard_data():
    print("Starting gold standard data generation for 2+ years...")
    
    # --- DYNAMICALLY FETCH MASTER DATA ---
    print("Fetching master data from Supabase...")
    product_master_data = supabase.table('product_master').select('*').execute().data
    df_products = pd.DataFrame(product_master_data)
    
    store_master_data = supabase.table('store_master').select('store_id, store_region').execute().data
    df_stores = pd.DataFrame(store_master_data)
    actual_store_ids = df_stores['store_id'].tolist()
    
    store_region_map = df_stores.set_index('store_id')['store_region'].to_dict()
    southern_regions = ['Southeast', 'West']
    trend_regions = ['West', 'Northeast']

    # --- GENERATION LOGIC ---
    all_transactions = []
    date_range = pd.to_datetime(pd.date_range(START_DATE, END_DATE))

    for _, product in df_products.iterrows():
        print(f"Generating data for: {product['product_name']}")
        
        for store_id in actual_store_ids:
            store_region = store_region_map.get(store_id)
            
            for day in date_range:
                baseline_units = random.randint(10, 50)
                day_of_week = day.dayofweek
                day_of_year = day.dayofyear
                days_from_start = (day - pd.to_datetime(START_DATE)).days
                
                weekly_multiplier = np.select([day_of_week >= 4], [1.7], default=1.0)
                
                seasonal_multiplier = 1.0
                era_multiplier = 1.0

                if product['product_era'] == 'New Era':
                    growth_rate = 0.005 if store_region in trend_regions else 0.002
                    era_multiplier = 1 + (days_from_start * growth_rate)
                
                if product['product_category'] == 'Ice Cream':
                    base_seasonality = np.sin(2 * np.pi * (day_of_year - 105) / 365) + 1.2
                    seasonal_multiplier = base_seasonality * 1.8
                else: # For Chocolate & Candy
                    if (day_of_year >= 30) and (day_of_year <= 45): seasonal_multiplier = 4.0
                    elif (day_of_year >= 85) and (day_of_year <= 105): seasonal_multiplier = 5.0
                    elif (day_of_year >= 285) and (day_of_year <= 304): seasonal_multiplier = 8.0
                    elif (day_of_year >= 335) and (day_of_year <= 359): seasonal_multiplier = 7.0
                
                is_promo_day = np.random.choice([True, False], p=[0.2, 0.8])
                promo_multiplier = random.uniform(2.0, 3.0) if is_promo_day else 1.0
                noise = np.random.randint(-3, 4)
                
                expected_total_units = int(np.maximum(0, baseline_units * weekly_multiplier * seasonal_multiplier * era_multiplier * promo_multiplier + noise))
                if expected_total_units == 0: continue
                
                num_transactions = random.randint(5, 15)
                transaction_units = np.random.multinomial(expected_total_units, np.ones(num_transactions)/num_transactions)
                for units in transaction_units:
                    if units == 0: continue
                    on_promotion_flag = False; sale_price = product['retail_price']
                    if is_promo_day and random.random() < 0.3:
                        on_promotion_flag = True
                        discount = random.choice([0.10, 0.15, 0.25])
                        sale_price = round(product['retail_price'] * (1 - discount), 2)
                    
                    # --- THE FIX IS HERE ---
                    all_transactions.append({
                        "created_at": day, 
                        "product_id": product['product_id'], # Changed product_id to product['product_id']
                        "store_id": store_id, 
                        "units_sold": units, 
                        "on_promotion": on_promotion_flag, 
                        "sale_price": sale_price
                    })

    final_df = pd.DataFrame(all_transactions)
    print(f"Generated {len(final_df)} total transactions.")
    return final_df




def upload_to_supabase(df):
    print("Preparing to upload to Supabase...")
    
    print("Clearing all existing data from 'sales_transactions' table...")
    supabase.table('sales_transactions').delete().neq('transaction_id', 0).execute()
    print("Table cleared.")

    df['created_at'] = df['created_at'].dt.strftime('%Y-%m-%dT%H:%M:%S%z')
    
    records = df.to_dict(orient='records')
    print(f"Uploading {len(records)} new records in chunks...")
    
    chunk_size = 1000
    for i in range(0, len(records), chunk_size):
        chunk = records[i:i + chunk_size]
        supabase.table('sales_transactions').insert(chunk).execute()
        print(f"Uploaded chunk {i // chunk_size + 1}...")
    
    print("âœ… Upload complete!")

if __name__ == "__main__":
    new_sales_data = generate_gold_standard_data()
    print("\nSample of generated data:")
    print(new_sales_data.head())
    
    confirm = input("\nARE YOU SURE you want to delete all existing sales data and replace it? (yes/no): ")
    if confirm.lower() == 'yes':
        upload_to_supabase(new_sales_data)
    else:
        print("Upload cancelled.")